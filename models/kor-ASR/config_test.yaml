dataloader:
  batch_size: 2
  num_workers: 100
  pin_memory: True
data:
  scp_dir: /home/hdd2/jenny/ASRToolkit/Self-Distillation-ASR/scp/kspon_aihub비대면/
  sample_rate: 16000
  n_mels: 80
  n_fft: 400
  win_length: 400
  hop_length: 160
  test_clean: True
  audio_feature_mean: /home/hdd2/jenny/ASRToolkit/Self-Distillation-ASR/models/stats/Ksponspeech345_비대면진료PAHA/train_mean.pt # <-- 계산 후 저장된 파일 경로
  audio_feature_std: /home/hdd2/jenny/ASRToolkit/Self-Distillation-ASR/models/stats/Ksponspeech345_비대면진료PAHA/train_std.pt   # <-- 계산 후 저장된 파일 경로
  augmentation:
    noise_mixing: false
    noise_dir: /home/hdd2/jenny/ASRToolkit/Self-Distillation-ASR/scp/noise_new.scp
    noise_prob: 0.3
    noise_level: 0.3

    rir_mixing: false
    rir_dir: /home/hdd2/jenny/ASRToolkit/Self-Distillation-ASR/scp/rir_new.scp
    rir_prob: 0.3
    RT_list: [0.3, 0.5, 0.7]

    specaugment: true
    time_mask_param: 100
    freq_mask_param: 27
    n_time_masks: 2
    n_freq_masks: 2
  
    speed_perturb: true
    speed_factors: [0.9, 1.0, 1.1]  # 0.9가 33%로 적용, 1.0이 33%로 적용, 1.1이 33%로 적용
    speed_prob: 0.8

    gaussian_noise: true
    gnoise_prob: 0.5
    gnoise_std: 0.1
  tokenizer: /home/hdd2/jenny/ASRToolkit/Self-Distillation-ASR/util/spm/bpe/kor_bpe5000.model
model:
  asr:
    encoder:
      type: "Conformer"
      input_dim: 80
      input_dropout_p: 0.1
      num_blocks: 17
      encoder_dim: 256
      pos_embed_type: "relpos"  # relpos, abspos
      dropout_rate: 0.1
      ff_expansion_factor: 4
      ff_activation_type: "swish"
      ff_dropout_p: 0.1
      attention_heads: 4
      att_dropout_p: 0.1
      cnn_module_kernel: 31
      conv_expansion_factor: 2
      conv_batchnorm: True  # True: Batch normalization in ConvModule, else LayerNorm
      conv_dropout_p: 0.1
      half_step_residual: True
    decoder:
      decoding_method: "greedy"  # greedy, beamsearch
      lm_fld: /home/hdd2/jenny/ASRToolkit/Self-Distillation-ASR/lm/librispeech/librispeech-4-gram
      beam_size: 2  # if ctc only, decoding method is greedy search (= no beam search)
      penalty: 0.3  # < 0: 너무 짧은 출력 억제, 0.0 ~ 0.2 : 일반적인 ASR, 0.3 이상: 너무 긴 출력 억제
      minlenratio: 0.1
      maxlenratio: 1.0 # 디코딩 출력의 최대 길이, len(encoder) * maxlenratio
      rnnlm: false
      lm_weight: 0.2
      type: "rnnt"  # ctc, rnnt, transformer, hybrid
      ctc_type: "builtin"  # builtin, cudnnctc, gtnctc
      ctc_weight: 0.0
      eprojs: 256      
      odim: 5000
      # rnnt
      dtype: gru  # lstm, gru
      dlayers: 1
      dunits: 640
      reduce: True
      dropout_rate: 0.1
      loss_function: "CE"  # KL_Div, CE
      lsm_weight: 0.1
    char_list:
    sym_space: " "
    sym_blank: "<blank>"
    report_cer: True
    report_wer: False
  distillation:
    using_distillation: False
    loss_type: "soft_l1"  # kl_div, soft_l1, mse
    temperature: 2.0
    alpha: 0.5
    target: "encoder"  # encoder, ctc

trainer:
  proj: "Ksponspeech + AIHub_비대면진료담화"
  exp_name: "rnnt decoder"
  log_dir: "logs"
  num_epochs: 100
  weight_decay: 1e-6
  warmup_epochs: 10
  precision: 16
  accumulate_grad_batches: 32
  gpus: 1
  gradient_clip_val: 1.0
  resume_from_checkpoint: false
  log_every_n_steps: 100
  val_check_interval: 1.0
  strategy: "ddp"  # ddp, ddp_spawn, deepspeed
  reload_dataloaders_every_n_epochs: 0
  ckpt_path: /home/hdd2/jenny/ASRToolkit/Self-Distillation-ASR/models/kor-ASR/models/epoch=03-val_wer=1.0000.ckpt
checkpoint:
  checkpoint_monitor: "val_loss"
  save_top_k: -1  # all models are saved
  model_save_path: "/home/hdd2/jenny/ASRToolkit/Self-Distillation-ASR/models/kor-ASR/models/clean_ASR.pth"
optimizer:
  type: "AdamW"
  op_lr: 5.0  # max : 2e-3
  max_epochs: 100
  warmup_steps: 25000
  scheduling_type: "lambda"  # cosine-annealing, warmup, lambda
