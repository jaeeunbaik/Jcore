"""
ğŸ–¤ğŸ° JaeEun Baik, 2025
"""
import torch
from torch.utils.data import Dataset
import logging # ë¡œê·¸ ì¶œë ¥ì„ ìœ„í•´ ì¶”ê°€
import sentencepiece as spm # SentencePiece ëª¨ë¸ ë¡œë“œë¥¼ ìœ„í•´ ì¶”ê°€
import os # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ì„ ìœ„í•´ ì¶”ê°€
from typing import List, Tuple # íƒ€ì… íŒíŠ¸ ì¶”ê°€


class PredictorDataset(Dataset):
    def __init__(self, data_config, subset, sos_id: int = 2, eos_id: int = 3): # SOS/EOS IDë¥¼ ì¸ìë¡œ ë°›ìŒ
        """
        Dataset for Next Token Prediction (Predictor Finetuning).
        
        Args:
            data_config: Configuration dictionary for data loading (expected to have scp_dir, tokenizer path)
            subset (str): Subset name (e.g., 'train', 'dev')
            sos_id (int): ID for Start-of-Sentence token.
            eos_id (int): ID for End-of-Sentence token.
        """
        super().__init__()
        self.data_config = data_config
        self.scp_path = self.data_config.scp_dir + f"{subset}_token.scp" # í…ìŠ¤íŠ¸ í† í° SCP íŒŒì¼ ê²½ë¡œ
        self.items = self._load_scp(self.scp_path) # í† í° ID ì‹œí€€ìŠ¤ë“¤ì„ ë¡œë“œ

        self.sos_id = sos_id
        self.eos_id = eos_id
        

    def _load_scp(self, scp_path: str) -> List[torch.Tensor]:
        """
        Load dataset manifest file where each line contains space-separated token IDs.
        
        Example line in scp_path: "10 20 30 40 50" (representing a sentence)
        """
        items = []
        if not os.path.exists(scp_path):
            logging.error(f"SCP file not found: {scp_path}")
            raise FileNotFoundError(f"SCP file not found: {scp_path}")

        with open(scp_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f):
                line = line.strip()
                if not line:
                    continue
                try:
                    # í† í° ID ë¬¸ìì—´ì„ ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ì •ìˆ˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    token_ids = list(map(int, line.split(' ')))
                    token_tensors = torch.tensor(token_ids, dtype=torch.int64) # LongTensorê°€ ë” ì¼ë°˜ì 
                    items.append(token_tensors) # 'token' í‚¤ ì—†ì´ ë°”ë¡œ í…ì„œë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                except ValueError as ve:
                    logging.warning(f"Skipping line {line_num + 1} due to ValueError (invalid token ID format): {line} - {ve}")
                except Exception as e:
                    logging.warning(f"Skipping line {line_num + 1} due to unexpected error: {line} - {e}")
        
        logging.info(f"Loaded {len(items)} token sequences from {scp_path}")
        return items
    
    def __len__(self) -> int:
        return len(self.items)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Returns input and target sequences for next token prediction.
        
        Returns:
            Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
            - input_tokens (torch.Tensor): Sequence for the Predictor input (e.g., [<s>, t1, t2, ..., tn-1])
            - input_lengths (torch.Tensor): Length of input_tokens
            - target_tokens (torch.Tensor): Target sequence for loss calculation (e.g., [t1, t2, ..., tn, </s>])
            - target_lengths (torch.Tensor): Length of target_tokens
        """
        original_tokens = self.items[idx] # ì´ë¯¸ torch.Tensorì„

        # SOSì™€ EOS í† í°ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
        # Predictor ì…ë ¥ì€ [<s>, t1, t2, ..., tn-1]
        # Loss íƒ€ê²Ÿì€ [t1, t2, ..., tn, </s>]
        
        # 1. Predictor ì…ë ¥ ì‹œí€€ìŠ¤: SOS + original_tokens
        input_for_predictor = torch.cat(
            (torch.tensor([self.sos_id], dtype=torch.int64), original_tokens), dim=0
        )
        input_for_predictor_len = len(input_for_predictor)

        # 2. Loss íƒ€ê²Ÿ ì‹œí€€ìŠ¤: original_tokens + EOS
        target_for_loss = torch.cat(
            (original_tokens, torch.tensor([self.eos_id], dtype=torch.int64)), dim=0
        )
        target_for_loss_len = len(target_for_loss)

        
        return input_for_predictor, input_for_predictor_len, target_for_loss, target_for_loss_len